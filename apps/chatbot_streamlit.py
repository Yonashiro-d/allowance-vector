import streamlit as st
import sys
from pathlib import Path

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from rag_config import RAGConfig

st.set_page_config(
    page_title="é€šå‹¤æ‰‹å½“è¦ç¨‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ",
    page_icon="ğŸ’¬",
    layout="wide"
)

st.title("ğŸ’¬ é€šå‹¤æ‰‹å½“æ”¯çµ¦è¦ç¨‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
st.markdown("é€šå‹¤æ‰‹å½“æ”¯çµ¦è¦ç¨‹ã«é–¢ã™ã‚‹è³ªå•ã«ãŠç­”ãˆã—ã¾ã™ã€‚")

if "messages" not in st.session_state:
    st.session_state.messages = []

if "deploy_client" not in st.session_state:
    with st.spinner("ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ä¸­..."):
        try:
            import mlflow.deployments
            config = RAGConfig()
            st.session_state.config = config
            st.session_state.deploy_client = mlflow.deployments.get_deploy_client("databricks")
        except Exception as e:
            st.error(f"åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            st.stop()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("è¨­å®š")
    
    if st.button("ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢", type="secondary"):
        st.session_state.messages = []
        st.rerun()
    
    st.markdown("---")
    st.markdown("### ä½¿ã„æ–¹")
    st.markdown("""
    1. ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã«è³ªå•ã‚’å…¥åŠ›
    2. ã€Œé€ä¿¡ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
    3. AIãŒè¦ç¨‹æ–‡æ›¸ã«åŸºã¥ã„ã¦å›ç­”ã—ã¾ã™
    """)
    
    st.markdown("---")
    st.markdown("### æƒ…å ±")
    if st.session_state.config:
        config = st.session_state.config
        st.markdown(f"**ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ**: {config.serving_endpoint_name}")
        st.markdown(f"**ã‚«ã‚¿ãƒ­ã‚°**: {config.catalog}")
        st.markdown(f"**ã‚¹ã‚­ãƒ¼ãƒ**: {config.schema}")
        st.markdown(f"**ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹**: {config.vector_index_name}")

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    with st.chat_message("user"):
        st.markdown(prompt)
    
    with st.chat_message("assistant"):
        with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
            try:
                messages = [
                    {"role": msg["role"], "content": msg["content"]}
                    for msg in st.session_state.messages
                ]
                
                response = st.session_state.deploy_client.predict(
                    endpoint=st.session_state.config.serving_endpoint_name,
                    inputs={"messages": messages}
                )
                
                if isinstance(response, dict) and "choices" in response:
                    answer = response["choices"][0]["message"]["content"]
                elif isinstance(response, dict) and "predictions" in response:
                    answer = response["predictions"][0] if isinstance(response["predictions"], list) else str(response["predictions"])
                else:
                    answer = str(response)
                
                st.markdown(answer)
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": answer
                })
                
            except Exception as e:
                error_msg = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
                st.error(error_msg)
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": error_msg
                })

